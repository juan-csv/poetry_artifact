[2024-03-12 12:07:45,898] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dag_ml_life_cycle.load_data manual__2024-03-12T17:07:43.215886+00:00 [queued]>
[2024-03-12 12:07:45,902] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dag_ml_life_cycle.load_data manual__2024-03-12T17:07:43.215886+00:00 [queued]>
[2024-03-12 12:07:45,902] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-03-12 12:07:45,902] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-03-12 12:07:45,902] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-03-12 12:07:45,908] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): load_data> on 2024-03-12 17:07:43.215886+00:00
[2024-03-12 12:07:45,912] {standard_task_runner.py:52} INFO - Started process 57225 to run task
[2024-03-12 12:07:45,917] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'dag_ml_life_cycle', 'load_data', 'manual__2024-03-12T17:07:43.215886+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/lifecycle_ml_example/dags/dag_ml_life_cycle.py', '--cfg-path', '/var/folders/t4/c2kdpvnj6r793w3k056dkc640000gp/T/tmp9ey9lyo2', '--error-file', '/var/folders/t4/c2kdpvnj6r793w3k056dkc640000gp/T/tmpi7khr64g']
[2024-03-12 12:07:45,918] {standard_task_runner.py:77} INFO - Job 10: Subtask load_data
[2024-03-12 12:07:45,952] {logging_mixin.py:109} INFO - Running <TaskInstance: dag_ml_life_cycle.load_data manual__2024-03-12T17:07:43.215886+00:00 [running]> on host 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa
[2024-03-12 12:07:45,978] {taskinstance.py:1424} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@example.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dag_ml_life_cycle
AIRFLOW_CTX_TASK_ID=load_data
AIRFLOW_CTX_EXECUTION_DATE=2024-03-12T17:07:43.215886+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-03-12T17:07:43.215886+00:00
[2024-03-12 12:07:45,979] {data_manager.py:27} INFO - Reading data from local store
[2024-03-12 12:07:46,026] {python.py:175} INFO - Done. Returned value was:            destination  passanger weather  ...  direction_same direction_opp  Y
0      No Urgent Place      Alone   Sunny  ...               0             1  1
1      No Urgent Place  Friend(s)   Sunny  ...               0             1  0
2      No Urgent Place  Friend(s)   Sunny  ...               0             1  1
3      No Urgent Place  Friend(s)   Sunny  ...               0             1  0
4      No Urgent Place  Friend(s)   Sunny  ...               0             1  0
...                ...        ...     ...  ...             ...           ... ..
12679             Home    Partner   Rainy  ...               1             0  1
12680             Work      Alone   Rainy  ...               0             1  1
12681             Work      Alone   Snowy  ...               1             0  0
12682             Work      Alone   Snowy  ...               0             1  0
12683             Work      Alone   Sunny  ...               1             0  0

[12684 rows x 26 columns]
[2024-03-12 12:07:46,055] {xcom.py:333} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config.
[2024-03-12 12:07:46,056] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 2135, in xcom_push
    XCom.set(
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/xcom.py", line 100, in set
    value = XCom.serialize_value(value)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/xcom.py", line 331, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2024-03-12 12:07:46,063] {taskinstance.py:1267} INFO - Marking task as FAILED. dag_id=dag_ml_life_cycle, task_id=load_data, execution_date=20240312T170743, start_date=20240312T170745, end_date=20240312T170746
[2024-03-12 12:07:46,069] {standard_task_runner.py:89} ERROR - Failed to execute job 10 for task load_data
Traceback (most recent call last):
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 2135, in xcom_push
    XCom.set(
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/xcom.py", line 100, in set
    value = XCom.serialize_value(value)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/site-packages/airflow/models/xcom.py", line 331, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/Users/macbook/anaconda3/envs/airflow_env/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2024-03-12 12:07:46,101] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-03-12 12:07:46,115] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
